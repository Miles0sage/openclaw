# OpenClaw Parallel Agent Execution Architecture

**Version:** 1.0
**Date:** 2026-02-17
**Status:** Design Document (Ready for Implementation)

---

## Executive Summary

This document describes the parallel execution system for OpenClaw's 3-agent architecture. The system allows the PM Agent to coordinate simultaneous execution of specialized tasks across CodeGen, Security/Pentest, and Database/Supabase agents, dramatically improving project completion times and resource utilization.

**Key Goals:**

- Enable true parallel task execution (not sequential)
- Maintain agent independence while enabling coordination
- Aggregate results for holistic response generation
- Handle failures gracefully (timeout, errors, retries)
- Track all parallel work for audit/billing purposes

---

## Current State Analysis

### Existing Architecture

```
gateway.py (FastAPI)
    â†“
agent_router.py (routes to single agent)
    â†“
project_manager (Claude Opus 4.6) [COORDINATOR]
    â†“
[Sequential handoff to other agents]
```

**Current Flow:** Serial execution through PM â†’ CodeGen â†’ Security â†’ back to PM

- **Latency:** ~20-30 seconds per project (total)
- **Bottleneck:** Each agent waits for previous agent to complete
- **Cost:** Inefficient token usage (context repetition)

### New Parallel Architecture

```
gateway.py (FastAPI)
    â†“
parallel_executor.py (NEW)
    â†“
[PM Coordinator] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“                                        â”‚
[Parallel Worker Pool Manager]              â”‚
    â”œâ”€â†’ [CodeGen Worker]   (Build tasks)    â”‚
    â”œâ”€â†’ [Security Worker]  (Audit tasks)    â”‚
    â””â”€â†’ [Supabase Worker]  (Data tasks)     â”‚
         â†“        â†“             â†“            â”‚
        Task    Task           Task         â”‚
        Queue  Queue           Queue        â”‚
         â†“        â†“             â†“            â”‚
    [Agent]  [Agent]       [Agent]         â”‚
                                            â”‚
         [Result Aggregator] â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
         Final Response
```

---

## Component Architecture

### 1. Parallel Executor (`parallel_executor.py`)

**Responsibility:** Manage parallel task execution and coordination

```python
class ParallelExecutor:
    """
    Orchestrates parallel execution of independent tasks across agents.
    - Routes tasks to worker pools
    - Tracks concurrent execution state
    - Aggregates results
    - Handles failures and timeouts
    """

    def __init__(self, config: ParallelExecutorConfig):
        self.pm_agent = PMAgent()              # Coordinator
        self.worker_pools = {
            'codegen': CodeGenWorkerPool(),    # 1-3 concurrent CodeGen tasks
            'security': SecurityWorkerPool(),  # 1-2 concurrent Security tasks
            'database': DatabaseWorkerPool()   # 1-2 concurrent Data tasks
        }
        self.active_executions = {}           # Track parallel runs
        self.result_aggregator = ResultAggregator()

    async def execute_parallel(
        self,
        tasks: List[ParallelTask],
        coordinator_context: Dict
    ) -> ParallelExecutionResult:
        """
        Execute multiple tasks in parallel.

        Args:
            tasks: List of tasks to execute (e.g., "build UI", "audit security", "setup db")
            coordinator_context: Context from PM (requirements, budget, etc.)

        Returns:
            Aggregated results from all parallel agents
        """
```

### 2. Worker Pools (`worker_pools.py`)

**Responsibility:** Manage concurrent execution for each agent type

```python
class WorkerPool:
    """Base worker pool for agent type"""

    def __init__(self, max_concurrent: int = 3, timeout_sec: int = 300):
        self.max_concurrent = max_concurrent
        self.task_queue = asyncio.Queue()
        self.active_tasks = {}
        self.completed_tasks = []

    async def enqueue_task(self, task: Task) -> str:
        """Add task to queue, return task_id"""

    async def wait_for_completion(
        self,
        task_ids: List[str],
        timeout_sec: int
    ) -> Dict[str, TaskResult]:
        """Wait for specific tasks to complete or timeout"""

class CodeGenWorkerPool(WorkerPool):
    """Specialized for code generation tasks"""
    MAX_CONCURRENT = 3  # Can handle 3 concurrent "build frontend", "build backend", "setup CI"

class SecurityWorkerPool(WorkerPool):
    """Specialized for security audits"""
    MAX_CONCURRENT = 2  # Lower concurrency (more thorough)

class DatabaseWorkerPool(WorkerPool):
    """Specialized for data tasks"""
    MAX_CONCURRENT = 2
```

### 3. Task Distribution Logic (`task_distributor.py`)

**Responsibility:** Route tasks to appropriate agent pool based on intent

```python
class TaskDistributor:
    """Routes tasks to correct worker pool"""

    CODEGEN_KEYWORDS = [
        'build', 'implement', 'code', 'api', 'function',
        'frontend', 'backend', 'deploy', 'git', 'testing'
    ]

    SECURITY_KEYWORDS = [
        'security', 'audit', 'vulnerability', 'pentest',
        'xss', 'csrf', 'injection', 'encryption'
    ]

    DATABASE_KEYWORDS = [
        'database', 'schema', 'migrate', 'query',
        'supabase', 'postgresql', 'backup', 'index'
    ]

    def distribute(self, task_description: str) -> WorkerPoolType:
        """
        Analyze task and route to correct pool.

        Returns:
            'codegen' | 'security' | 'database' | 'multi' (multiple agents)
        """
        score = self.score_task(task_description)
        return score.best_pool

class ParallelTask:
    """Represents a single unit of parallel work"""
    id: str
    pool_type: str              # 'codegen', 'security', 'database'
    description: str            # What to do
    context: Dict               # Task-specific context
    max_retries: int = 2
    timeout_sec: int = 300
    status: str = 'pending'     # pending, running, completed, failed, timeout
    result: Optional[Dict] = None
    error: Optional[str] = None
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
```

### 4. Result Aggregator (`result_aggregator.py`)

**Responsibility:** Combine results from parallel agents into coherent response

```python
class ResultAggregator:
    """Aggregates parallel agent results"""

    def aggregate(
        self,
        pm_context: Dict,
        parallel_results: Dict[str, TaskResult],
        failed_tasks: List[str] = None
    ) -> AggregatedResult:
        """
        Combine results from all agents.

        Flow:
        1. Validate all results received
        2. Resolve conflicts/dependencies
        3. Build unified context
        4. Generate final response
        5. Log costs/metrics

        Returns:
            Final response ready for client
        """

    def _resolve_conflicts(
        self,
        codegen_result: Dict,
        security_result: Dict,
        database_result: Dict
    ) -> Dict:
        """Handle cases where agents have conflicting recommendations"""
        # Example: CodeGen suggests approach, Security flags risk
        # Resolution: Add security layer to CodeGen approach

    def _detect_dependencies(
        self,
        results: Dict[str, TaskResult]
    ) -> List[Dependency]:
        """Detect task dependencies in results"""
        # Example: DB schema affects API design

    def _build_unified_context(
        self,
        results: Dict[str, TaskResult]
    ) -> Dict:
        """Build holistic view from all agent outputs"""

class AggregatedResult:
    codegen_output: Dict         # Code, architecture, implementation
    security_output: Dict        # Vulnerabilities, recommendations, fixes
    database_output: Dict        # Schema, migrations, optimizations
    conflicts_detected: List[str]
    dependencies: List[Dependency]
    recommendations: List[str]   # Unified recommendations from all agents
    summary: str                 # Human-readable summary
    total_tokens_used: int
    total_cost: float
```

### 5. PM Coordinator Role (`pm_coordinator.py`)

**Responsibility:** PM agent orchestrates parallel work (new role)

```python
class PMCoordinator:
    """
    PM's new responsibilities in parallel execution:
    1. Decompose incoming request into parallel tasks
    2. Create task definitions
    3. Hand off to parallel executor
    4. Wait for results
    5. Generate final client communication
    """

    async def decompose_into_parallel_tasks(
        self,
        user_request: str,
        session_context: Dict
    ) -> List[ParallelTask]:
        """
        Use Claude Opus reasoning to break down request.

        Example:
        User: "Build a restaurant website with secure booking"

        Decomposition:
        - CodeGen: "Build Next.js frontend with menu, gallery, booking form"
        - CodeGen: "Build FastAPI backend with booking API"
        - Security: "Audit booking flow for SQL injection, XSS, CSRF"
        - Database: "Create Supabase schema for reservations"

        Returns:
            List of independent parallel tasks
        """

    async def coordinate_execution(
        self,
        tasks: List[ParallelTask]
    ) -> CoordinationResult:
        """
        1. Send tasks to parallel executor
        2. Monitor progress
        3. Handle timeouts/failures
        4. Collect results
        5. Synthesize final response
        """

    async def synthesize_final_response(
        self,
        aggregated_result: AggregatedResult
    ) -> str:
        """
        Generate final client-facing message combining:
        - What was built (CodeGen)
        - Security measures (Security)
        - Data model (Database)
        - Timeline/milestones
        - Next steps
        """
```

---

## Task Distribution Examples

### Example 1: Website Build Request

**User Request:**

```
"Build a restaurant website with online booking and secure payments"
```

**PM Decomposition:**

```
Parallel Tasks:
1. CodeGen (Build Frontend)
   - Create Next.js frontend with menu display, gallery, booking form
   - Integrate Stripe for payments
   - Deploy to Vercel

2. CodeGen (Build Backend)
   - Create FastAPI backend with REST API for menu, bookings, payments
   - Setup authentication (JWT)
   - Deploy to cloud

3. Security (Audit)
   - Test payment flow for fraud vulnerabilities
   - Check booking form for SQL injection, XSS
   - Verify authentication implementation
   - Check OWASP Top 10

4. Database (Setup)
   - Design Supabase schema for restaurants, menus, bookings, payments
   - Create migrations
   - Setup realtime subscriptions for booking updates
```

**Execution Timeline:**

```
t=0s   PM decomposes request
t=1s   All 4 tasks queued in parallel
t=5s   CodeGen starts both tasks (Frontend + Backend run simultaneously)
       Security starts audit
       Database starts schema design
t=45s  CodeGen Frontend completes
t=90s  CodeGen Backend completes
t=120s Security audit completes
t=60s  Database schema completes
t=121s Results aggregated
       - Security flags CSRF vulnerability in booking
       - CodeGen + Security align on fix
       - All systems ready
t=125s PM synthesizes final response
t=126s Client receives complete solution
```

**Serial vs Parallel:**

- Serial (current): ~180 seconds (Frontend 45s + Backend 45s + Security 120s + Audit 120s sequentially)
- Parallel (new): ~126 seconds (all run concurrently, bottleneck is Security Audit at 120s)
- **Savings: 54 seconds (30% faster)**

### Example 2: Supabase Data Migration

**User Request:**

```
"Migrate our PostgreSQL data to Supabase and optimize queries"
```

**Parallel Tasks:**

```
1. CodeGen (Migration Script)
   - Write pg_dump export
   - Transform data format
   - Create Supabase import script

2. Database (Schema Optimization)
   - Analyze query patterns
   - Add indexes on common queries
   - Optimize schema for Realtime

3. Security (Data Audit)
   - Check for PII exposure
   - Verify encryption in transit
   - Validate access control rules
```

### Example 3: Security-Only Request

**User Request:**

```
"Audit this website for vulnerabilities"
```

**Decomposition:**

```
Only Security pool activated:
1. Pentest AI: OWASP Top 10 scan
2. Pentest AI: API endpoint testing
3. Pentest AI: Database injection testing

(CodeGen/Database stay idle - PM recognizes security-only scope)
```

---

## Failure Handling

### Timeout Strategy

```
ParallelTask Lifecycle:
  pending â†’ running â†’ completed âœ“
              â†“
           timeout after 300s
              â†“
        retry (max 2x)
              â†“
         failed after retries
```

**Example Timeout Scenario:**

```
t=0s   All tasks start
t=60s  CodeGen Frontend complete
t=120s CodeGen Backend times out
       - Auto-retry begins
t=180s Still timing out
       - Retry complete (2/2)
       - Task marked FAILED

At aggregation:
- Have: Frontend code, Security audit, DB schema
- Missing: Backend code
- Strategy: Return partial results with "Backend pending" note
- Cost: Refund partial fee to client
```

### Error Handling

```python
class FailureHandler:
    """Handle various failure modes"""

    async def handle_task_failure(
        self,
        task: ParallelTask,
        error: Exception
    ) -> FailureResolution:
        """
        Strategies:
        1. RETRY: Auto-retry same task (max 2x)
        2. FALLBACK: Use simpler agent/model for this task
        3. ESCALATE: Hand to PM for manual intervention
        4. SKIP: Continue without this result (partial delivery)
        5. REFUND: Charge only for completed work
        """

    async def handle_timeout(
        self,
        task: ParallelTask
    ) -> FailureResolution:
        """Task exceeded time limit"""

    async def handle_agent_unavailable(
        self,
        pool_type: str
    ) -> FailureResolution:
        """Agent crashed/not responding"""
```

---

## Configuration

### `config.json` Extensions

```json
{
  "parallel_execution": {
    "enabled": true,
    "worker_pools": {
      "codegen": {
        "max_concurrent": 3,
        "timeout_sec": 300,
        "model": "MiniMax-M2.5",
        "max_retries": 2
      },
      "security": {
        "max_concurrent": 2,
        "timeout_sec": 300,
        "model": "qwen2.5-coder:14b",
        "max_retries": 2
      },
      "database": {
        "max_concurrent": 2,
        "timeout_sec": 180,
        "model": "MiniMax-M2.5-Lightning",
        "max_retries": 2
      }
    },
    "pm_coordinator": {
      "decomposition_model": "claude-opus-4-6-20250514",
      "reasoning_effort": "high",
      "max_tasks_per_decomposition": 6
    },
    "result_aggregation": {
      "strategy": "intelligent_merge",
      "conflict_resolution": "security_first"
    }
  }
}
```

---

## Execution Flow - Detailed

### Phase 1: Request Arrives

```
POST /api/chat with body:
{
  "message": "Build a restaurant website with booking",
  "sessionKey": "user123",
  "project": "delhi-palace"
}

â†“

gateway.py receives request
  - Loads session history
  - Extracts user intent
  - Creates execution_id = "exec_user123_timestamp"
```

### Phase 2: PM Decomposition

```
PM Agent (Claude Opus 4.6):
  Input: User message + session context + project info

  Task: "Decompose this into parallel work"

  Thinking (Extended):
    - What are the main work streams?
    - Which can run in parallel?
    - Dependencies between tasks?
    - Time/resource budget?

  Output:
  {
    "parallel_tasks": [
      {
        "id": "task_1",
        "pool": "codegen",
        "description": "Build Next.js restaurant website with menu & gallery",
        "context": { "framework": "nextjs", "deadline_hours": 8 },
        "priority": 1
      },
      {
        "id": "task_2",
        "pool": "codegen",
        "description": "Build FastAPI backend with booking & payment APIs",
        "context": { "framework": "fastapi", "deadline_hours": 6 },
        "priority": 2
      },
      {
        "id": "task_3",
        "pool": "security",
        "description": "Security audit: payments, booking, XSS/CSRF",
        "context": { "focus": "payment_security" },
        "priority": 2
      },
      {
        "id": "task_4",
        "pool": "database",
        "description": "Design Supabase schema for restaurants, menus, orders",
        "context": { "tables": ["restaurants", "menus", "orders"] },
        "priority": 1
      }
    ],
    "dependencies": [
      { "requires": "task_2", "blocks": "task_3" },
      { "requires": "task_4", "enhances": "task_2" }
    ],
    "total_estimated_tokens": 180000,
    "estimated_cost": 12.50
  }
```

### Phase 3: Parallel Execution

```
parallel_executor.execute_parallel(tasks)

â†“

[Enqueue Phase]
  Task 1 â†’ codegen queue (Frontend build)
  Task 2 â†’ codegen queue (Backend build)
  Task 3 â†’ security queue (Audit)
  Task 4 â†’ database queue (Schema)

â†“

[Execution Phase - All Concurrent]
  t=0s   Workers pick up tasks from queues
  t=5s   CodeGen processes both tasks simultaneously
         Security begins audit protocol
         Database analyzes schema requirements

  t=45s  CodeGen Frontend COMPLETE
         - Returns: Next.js app code, components, styling
         - Stores in execution.results['task_1']

  t=60s  Database COMPLETE
         - Returns: Supabase schema, migrations, indexes
         - Stores in execution.results['task_4']

  t=90s  CodeGen Backend COMPLETE
         - Returns: FastAPI routes, database models, auth
         - Stores in execution.results['task_2']
         - Now task_3 unblocked (can use backend code for audit)

  t=150s Security COMPLETE
         - Returns: Vulnerabilities found, security recommendations
         - Stores in execution.results['task_3']

â†“

[All tasks complete]
execution.all_completed = true
execution.total_duration = 150s
execution.total_tokens = 185000
execution.total_cost = 12.75
```

### Phase 4: Result Aggregation

```
result_aggregator.aggregate(results)

â†“

[Validation]
  All 4 tasks present âœ“
  No timeouts âœ“
  No errors âœ“

â†“

[Conflict Detection]
  CodeGen suggested: "Use JWT for auth"
  Security recommended: "Use JWT + rate limiting"
  â†’ Conflict: RESOLVED (add rate limiting to CodeGen design)

â†“

[Dependency Resolution]
  CodeGen Backend depends on Database schema
  â†’ Database schema already included
  â†’ Backend can use optimal schema design

â†“

[Unified Context Build]
  Merged output:
  {
    "frontend_code": "...",
    "backend_code": "...",
    "database_schema": "...",
    "security_findings": "3 medium, 1 low",
    "applied_fixes": ["rate_limiting", "csrf_tokens"],
    "deployment_ready": true
  }

â†“

[Cost Calculation]
  CodeGen tokens: 140000 tokens
  Security tokens: 25000 tokens
  Database tokens: 20000 tokens
  PM tokens: 15000 tokens (decomposition + synthesis)
  Total: 200000 tokens
  Total cost: $2.80 (Opus + MiniMax mixed rates)
```

### Phase 5: PM Synthesis

```
PM Agent synthesizes final response:

Input: aggregated_result (all agent outputs + conflicts resolved)

Task: "Create final client message combining all work"

Output Message:
---
ðŸŽ¯ **Restaurant Website Ready!**

**What We Built:**
âœ… **Frontend** (Next.js + Vercel)
- Modern restaurant website with menu gallery
- Online booking form (real-time updates)
- Responsive design (mobile-first)
- Fast loading (optimized images)

âœ… **Backend** (FastAPI + Cloud)
- REST API for menu, bookings, payments
- JWT authentication
- Rate limiting (security hardened)
- Database optimization (indexed queries)

âœ… **Database** (Supabase PostgreSQL)
- Schema: Restaurants â†’ Menus â†’ Bookings
- Real-time subscriptions for order updates
- Automated backups
- Row-level security policies

âœ… **Security Audit**
- 3 medium vulnerabilities found & fixed
  â€¢ CSRF protection on booking form
  â€¢ XSS sanitization on review fields
  â€¢ SQL injection prevention in queries
- All OWASP Top 10 tested
- Payment flow secured with Stripe best practices

**Timeline:** 2.5 minutes (parallel execution!)
**Cost:** $2.80
**Next:** Deploy to production today

â€” ðŸŽ¯ Cybershield PM
---

â†“

gateway.py sends response to client
â†“
cost_tracker logs: $2.80 to project
â†“
Session saved with results
```

---

## API Endpoints (New)

### POST /api/execute-parallel

```
Request:
{
  "message": "user request",
  "sessionKey": "user123",
  "project": "delhi-palace",
  "force_parallel": false
}

Response:
{
  "execution_id": "exec_user123_1708157435",
  "status": "executing",
  "parallel_tasks": 4,
  "estimated_duration_sec": 150,
  "estimated_cost": "$2.80",
  "task_details": [
    {
      "id": "task_1",
      "pool": "codegen",
      "status": "running",
      "progress_percent": 30
    },
    ...
  ]
}
```

### GET /api/execution/{execution_id}

```
Response:
{
  "execution_id": "exec_user123_1708157435",
  "status": "completed",
  "started_at": "2026-02-17T06:30:35Z",
  "completed_at": "2026-02-17T06:32:25Z",
  "duration_sec": 150,
  "results": {
    "codegen": { ... },
    "security": { ... },
    "database": { ... }
  },
  "final_response": "string",
  "cost": "$2.80",
  "quality_score": 0.98
}
```

---

## Files to Create/Modify

### New Files (8 total)

```
/root/openclaw/parallel_executor.py          (450 LOC)
  - ParallelExecutor class
  - Task definition & tracking
  - Execution orchestration

/root/openclaw/worker_pools.py               (380 LOC)
  - WorkerPool base class
  - CodeGenWorkerPool
  - SecurityWorkerPool
  - DatabaseWorkerPool

/root/openclaw/task_distributor.py           (220 LOC)
  - TaskDistributor
  - Task routing logic
  - Intent classification for parallel tasks

/root/openclaw/result_aggregator.py          (320 LOC)
  - ResultAggregator
  - Conflict resolution
  - Dependency detection
  - Unified context building

/root/openclaw/pm_coordinator.py             (380 LOC)
  - PMCoordinator (new PM role)
  - Decomposition logic
  - Response synthesis
  - Executive summary generation

/root/openclaw/failure_handler.py            (280 LOC)
  - Timeout handling
  - Retry logic
  - Graceful degradation

/root/openclaw/test_parallel_executor.py     (650 LOC)
  - Unit tests for all components
  - Integration tests (end-to-end)
  - Mock agent responses
  - Failure scenario tests

/root/openclaw/PARALLEL-EXECUTION-GUIDE.md   (450 LOC)
  - User guide
  - Configuration examples
  - Troubleshooting
```

### Modified Files (3 total)

```
/root/openclaw/config.json
  - Add parallel_execution section
  - Worker pool configurations
  - PM coordinator settings

/root/openclaw/gateway.py
  - New POST /api/execute-parallel endpoint
  - New GET /api/execution/{execution_id} endpoint
  - Session handling for parallel results
  - Cost tracking integration

/root/openclaw/agent_router.py
  - Add routing rule for "parallel" intent
  - Detect when parallel execution is beneficial
  - Route to parallel_executor instead of single agent
```

---

## Performance Characteristics

### Latency Comparison

| Scenario                  | Serial (Current) | Parallel (New) | Speedup |
| ------------------------- | ---------------- | -------------- | ------- |
| Small task (web page)     | 45s              | 45s            | 1.0x    |
| Medium task (REST API)    | 120s             | 90s            | 1.33x   |
| Large task (full website) | 240s             | 150s           | 1.6x    |
| Complex task + security   | 360s             | 180s           | 2.0x    |

### Token/Cost Efficiency

```
Serial Approach:
  PM describes task â†’ CodeGen builds â†’ mentions outputs back
  Token usage: Initial 5K + CodeGen 50K + context repetition 10K = 65K

Parallel Approach:
  PM decomposes 10K â†’ All agents build independently (60K total)
  Result aggregation 5K = 75K tokens

  BUT: Parallel completes faster = lower API costs per minute
  And: Better quality (parallel review by Security)
  Net: Same/slightly higher tokens, but better outcomes
```

### Scalability

```
Current bottleneck: Single agent at a time
  Max throughput: 1 project at a time (serialized)

With parallel execution:
  Can handle 2-3 projects per PM (context-dependent)
  Each project fully parallelized internally

Future (multi-PM): 5+ concurrent projects
```

---

## Critical Design Decisions

### 1. Why Not Use Threads?

**Decision:** Use `asyncio` (async/await) instead of threads

**Rationale:**

- Agents are I/O-bound (waiting for API responses), not CPU-bound
- Asyncio lighter weight (no GIL contention)
- Better integration with FastAPI (async framework)
- Simpler error handling with asyncio

### 2. Why PM Decomposes (Not Automatic)?

**Decision:** PM agent decides task decomposition, not a rule-based system

**Rationale:**

- PM has context (budget, deadline, client preferences)
- Claude reasoning finds non-obvious parallelization opportunities
- Flexible: Some projects benefit from different decomposition
- Maintainable: No complex rule engine to maintain

### 3. Why Aggregate at End (Not Real-Time)?

**Decision:** Collect all results before synthesis, don't stream

**Rationale:**

- Enables conflict detection (can't resolve conflicts with incomplete data)
- Better aggregation (can see full picture)
- Simpler for client (one coherent response)
- Can still stream progress via WebSocket if needed later

### 4. What About Agent Disagreements?

**Decision:** "Security-first" conflict resolution

**Rationale:**

- If Security flags risk, honor it (client safety first)
- If CodeGen suggests approach, Security can add guardrails
- PM makes final call in synthesize phase if unresolvable

---

## Migration Path

### Phase 1: Foundation (Week 1)

- Create `parallel_executor.py`, `worker_pools.py`
- Add unit tests
- Deploy without making it default

### Phase 2: Integration (Week 2)

- Connect to `gateway.py`
- Create `/api/execute-parallel` endpoint
- Test with mock agents

### Phase 3: Production (Week 3)

- Real agent integration
- Cost tracking
- Monitor latency/quality
- Gradually shift traffic to parallel

### Phase 4: Optimization (Week 4)

- Tune worker pool sizes
- Optimize result aggregation
- A/B test parallel vs serial

---

## Testing Strategy

### Unit Tests

```python
# test_parallel_executor.py
- test_execute_basic_tasks()
- test_worker_pool_queuing()
- test_task_distribution()
- test_result_aggregation()
- test_conflict_detection()
- test_timeout_handling()
- test_retry_logic()
- test_pm_decomposition()
- test_cost_calculation()
```

### Integration Tests

```python
# test_parallel_integration.py (Mock Agents)
- test_end_to_end_website_build()
- test_security_audit_parallel()
- test_failure_recovery()
- test_cost_tracking()
- test_session_persistence()
```

### Load Tests

```python
# test_parallel_load.py
- test_10_concurrent_executions()
- test_worker_pool_under_load()
- test_queue_saturation()
```

---

## Monitoring & Observability

### Metrics to Track

```python
# prometheus metrics
parallel_execution_duration_seconds     # Histogram
parallel_execution_total_tasks          # Counter
parallel_execution_succeeded            # Counter
parallel_execution_failed               # Counter
parallel_execution_timeout              # Counter
worker_pool_queue_length                # Gauge
worker_pool_active_tasks                # Gauge
result_aggregation_conflicts            # Counter
```

### Logging

```
2026-02-17 06:30:35 [PM] Decomposing: "Build restaurant website"
2026-02-17 06:30:36 [EXECUTOR] Created 4 parallel tasks
2026-02-17 06:30:36 [CODEGEN] Queued task_1 (frontend)
2026-02-17 06:30:36 [CODEGEN] Queued task_2 (backend)
2026-02-17 06:30:36 [SECURITY] Queued task_3 (audit)
2026-02-17 06:30:36 [DATABASE] Queued task_4 (schema)
2026-02-17 06:30:40 [CODEGEN] Started task_1
2026-02-17 06:30:40 [DATABASE] Started task_4
2026-02-17 06:30:50 [SECURITY] Started task_3 (after dependency ready)
2026-02-17 06:31:15 [CODEGEN] Completed task_1 (45s, 25K tokens)
2026-02-17 06:31:35 [DATABASE] Completed task_4 (59s, 8K tokens)
2026-02-17 06:32:10 [CODEGEN] Completed task_2 (90s, 65K tokens)
2026-02-17 06:32:25 [SECURITY] Completed task_3 (95s, 18K tokens)
2026-02-17 06:32:26 [AGGREGATOR] Detected 1 conflict (security + codegen)
2026-02-17 06:32:27 [AGGREGATOR] Resolved: Added rate_limiting to backend
2026-02-17 06:32:28 [PM] Synthesizing final response...
2026-02-17 06:32:30 [PM] Complete! Cost: $2.80, Duration: 155s
```

---

## Future Enhancements (Not in v1.0)

### 1. Smart Task Scheduling

- Detect dependencies between tasks
- Schedule in optimal order
- Avoid unnecessary blocking

### 2. Dynamic Pool Sizing

- Monitor execution time
- Auto-scale worker pools based on backlog
- Tune based on workload patterns

### 3. Hybrid Parallel+Serial

- Some tasks should run serially (e.g., Database migrations must sequence)
- Support DAG execution (directed acyclic graph)

### 4. Multi-PM Support

- Multiple PM agents for different project types
- Specialized decomposers (e.g., "API specialist PM" vs "Website PM")

### 5. Streaming Results

- Stream results from parallel agents to client real-time
- Show progress: "Frontend 30%... Backend starting..."
- Improve perceived latency

### 6. Caching & Reuse

- Cache task results (e.g., "Security audit for Next.js")
- Reuse between projects
- Significant cost savings (40-50% for similar projects)

---

## Success Criteria

### v1.0 MVP

- [ ] All 5 new files created and tested
- [ ] Unit test coverage: >85%
- [ ] Integration tests passing
- [ ] Parallel execution 1.5x faster than serial for large projects
- [ ] Backward compatible (serial still works)
- [ ] Cost tracking accurate
- [ ] No breaking changes to gateway API
- [ ] Documentation complete

### Production Readiness

- [ ] 24-hour load test (no crashes)
- [ ] Failure handling tested (timeouts, agent crashes, errors)
- [ ] Security audit passed
- [ ] Cost savings validated (>20% for average project)
- [ ] Monitoring/alerting working
- [ ] Runbook for troubleshooting

---

## Summary

This architecture enables true parallel execution of specialized tasks while maintaining the PM's coordinating role. The key insight is that many projects have independent work streams (frontend vs backend vs security vs data) that can execute simultaneously, reducing total completion time by 40-60% while improving quality through parallel review and validation.

The system is designed to be transparent to clientsâ€”they see one coherent response synthesized from parallel agentsâ€”while internally optimizing for speed and cost.
